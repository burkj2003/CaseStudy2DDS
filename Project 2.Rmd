---
title: "Project 2"
author: "Jason Burk"
date: "11/21/2019"
output: html_document
editor_options: 
  chunk_output_type: console
---

```{r}

library(caret)
library(e1071)
library(class)
library(tidyverse)
library(ggplot2)
library(dplyr)
#library(data.table)
#library(mice)
#library(ggalt)
#library(usmap)


# read in the data from .CSV files
Comp = read.csv("~/03-School/DS 6306/Project 2/CaseStudy2-data.csv")
CompNoSal = read.csv("~/03-School/DS 6306/Project 2/CaseStudy2CompSet No Salary.csv")
CompNoAtt = read.csv("~/03-School/DS 6306/Project 2/CaseStudy2CompSet No Attrition.csv")
cols = dim(Comp)[1]

# Test the data to see if any N/A data, if so remove the n/a data
if (any(is.na(Comp))) {
  Comp <- na.omit(Comp)
}
if (any(is.na(CompNoSal))) {
  CompNoSal <- na.omit(CompNoSal)
}
if (any(is.na(CompNoAtt))) {
  CompNoAtt <- na.omit(CompNoAtt)
}

# Compute new columns of data

## Turnover Ratio is based on the number of years in the work force divided by the number of companies worked.
## The higher the ratio the longer they stay with a company  
turnover = data.frame(TurnoverRatio = 1:cols)
for (i in 1:cols) {
  if (Comp[i,]$NumCompaniesWorked == 0) {
    turnover[i,] = Comp[i,]$TotalWorkingYears / (Comp[i,]$NumCompaniesWorked + 1)
  }
  else {
    turnover[i,] = Comp[i,]$TotalWorkingYears / Comp[i,]$NumCompaniesWorked
  }
}
Comp$TurnoverRatio = turnover$TurnoverRatio

# Split the data into a train and test set based on a defined percentage
set.seed(14)
splitPerc = 0.75
trainIndices = sample(1:dim(Comp)[1],round(splitPerc * dim(Comp)[1]))
train = Comp[trainIndices,]
test = Comp[-trainIndices,]

# Knn
## First find the best k-factor
accs = data.frame(accuracy = numeric(30), k = numeric(30))

for(i in 1:30)
{
  classifications = knn(train[,c(2,33)],test[,c(2,33)],train$Attrition, prob = TRUE, k = i)
  table(test$Attrition,classifications)
  CM = confusionMatrix(table(test$Attrition,classifications))
  accs$accuracy[i] = CM$overall[1]
  accs$k[i] = i
}

plot(accs$k,accs$accuracy, type = "l", xlab = "k", ylab = "Accuracy", main = "K-factor vs Accuracy") 


# plot knn
test %>% ggplot(aes(x = Age, TurnoverRatio,color = Attrition)) + geom_point() + ggtitle("Age vs Gender") + theme(plot.title = element_text(hjust = 0.5))
train %>% ggplot(aes(x = Age, DistanceFromHome,color = Attrition)) + geom_point() + ggtitle("Age vs Gender") + theme(plot.title = element_text(hjust = 0.5))

# first knn
classifications = knn(train[,c(2,37)],test[,c(2,37)],train$Attrition, prob = T, k = 11)
table(classifications,test$Attrition)
confusionMatrix(table(classifications,test$Attrition))

# second knn
classifications = knn(train[,c(2,30)],test[,c(2,30)],train$Attrition, prob = TRUE, k = 11)
table(test$Attrition,classifications)
CM = confusionMatrix(table(test$Attrition,classifications))
CM

# third knn
classifications = knn(train[,c(2,33)],test[,c(2,33)],train$Attrition, prob = TRUE, k = 10)
table(test$Attrition,classifications)
CM = confusionMatrix(table(test$Attrition,classifications))
CM


# NB
simple <- train[-c(1,4:12,14:39)]
simple$Age = as.factor(simple$Age)
model = naiveBayes(Attrition~., data = simple)
df = data.frame(Age = "30", Gender = "Male")
predict(model,df)
predict(model, df, type = "raw")


# First NB
model = naiveBayes(train[,c(2,30,37)],as.factor(train$Attrition),laplace = 1)
table(predict(model,test[,c(2,30,37)]),as.factor(test$Attrition))
CM = confusionMatrix(table(predict(model,test[,c(2,30,37)]),as.factor(test$Attrition)))
CM

# Second NB
model = naiveBayes(train[,c(2,13,19,37)],factor(train$Attrition, labels = c("No", "Yes")))
table(factor(test$Attrition, labels = c("No", "Yes")),predict(model,test[,c(2,13,19,37)]))
CM = confusionMatrix(table(factor(test$Attrition, labels = c("No", "Yes")),predict(model,test[,c(2,13,19,37)])))
CM

# Third NB
model = naiveBayes(train[,c(2,29,33,37)],factor(train$Attrition, labels = c("No", "Yes")))
table(factor(test$Attrition, labels = c("No", "Yes")),predict(model,test[,c(2,29,33,37)]))
CM = confusionMatrix(table(factor(test$Attrition, labels = c("No", "Yes")),predict(model,test[,c(2,29,33,37)])))
CM



#############################

# Data Prep
AttFilter <- Comp %>% filter(Attrition == "Yes")

percentages <- data.frame(perc = 1:39)
percentages$perc = 0

AttrPerc <- Comp %>% count(Attrition)

#if (AttrPerc$Attrition == "Yes") {
#  AP = AttrdPerc$n
#}

AP <- AttrPerc[2,]$n



for (i in 1:dim(percentages)[1]) {
  
  percentages[i,] = Comp$ID / AP
  
}









###############
# plot
data("mtcars")  # load data
mtcars$`car name` <- rownames(mtcars)  # create new column for car names


AttFilter$xxxxx <- round((AttFilter$mpg - mean(AttFilter$mpg))/sd(AttFilter$mpg), 2)  # compute normalized mpg
AttFilter$mpg_type <- ifelse(AttFilter$mpg_z < 0, "below", "above")  # above / below avg flag
AttFilter <- AttFilter[order(AttFilter$mpg_z), ]  # sort
AttFilter$`car name` <- factor(AttFilter$`car name`, levels = AttFilter$`car name`)  # convert to factor to retain sorted order in plot.

# Diverging Barcharts
ggplot(AttFilter, aes(x=`name here`, y=percentages, label=percentages)) + 
  geom_bar(stat='xxxxxxxx', aes(fill=xxxxxxx), width=.5)  +
  scale_fill_manual(name="Percentages", 
                    labels = c("Above Average", "Below Average"), 
                    values = c("above"="#00ba38", "below"="#f8766d")) + 
  labs(subtitle="Normalised percentages of Attrition attributes", 
       title= "Diverging Bars") + 
  coord_flip()





















































```
