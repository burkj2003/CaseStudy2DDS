---
title: "Project 2"
author: "Jason Burk"
date: "11/21/2019"
output: html_document
editor_options: 
  chunk_output_type: console
---

```{r}

library(caret)
library(e1071)
library(class)
library(tidyverse)
library(ggplot2)
library(dplyr)
library(GGally)
#library(data.table)
#library(mice)
#library(ggalt)
#library(usmap)


# read in the data from .CSV files
Comp = read.csv("~/03-School/DS 6306/Project 2/CaseStudy2-data.csv")
CompNoSal = read.csv("~/03-School/DS 6306/Project 2/CaseStudy2CompSet No Salary.csv")
CompNoAtt = read.csv("~/03-School/DS 6306/Project 2/CaseStudy2CompSet No Attrition.csv")
cols = dim(Comp)[1]

# Test the data to see if any N/A data, if so remove the n/a data
if (any(is.na(Comp))) {
  Comp <- na.omit(Comp)
}
if (any(is.na(CompNoSal))) {
  CompNoSal <- na.omit(CompNoSal)
}
if (any(is.na(CompNoAtt))) {
  CompNoAtt <- na.omit(CompNoAtt)
}

# Compute new columns of data

## Turnover Ratio is based on the number of years in the work force divided by the number of companies worked.
## The higher the ratio the longer they stay with a company  
turnover = data.frame(TurnoverRatio = 1:cols)
for (i in 1:cols) {
  if (Comp[i,]$NumCompaniesWorked == 0) {
    turnover[i,] = Comp[i,]$TotalWorkingYears / (Comp[i,]$NumCompaniesWorked + 1)
  }
  else {
    turnover[i,] = Comp[i,]$TotalWorkingYears / Comp[i,]$NumCompaniesWorked
  }
}
Comp$TurnoverRatio = turnover$TurnoverRatio

# Split the data into a train and test set based on a defined percentage
set.seed(14)
splitPerc = 0.75
trainIndices = sample(1:dim(Comp)[1],round(splitPerc * dim(Comp)[1]))
train = Comp[trainIndices,]
test = Comp[-trainIndices,]

############################

stay <- Comp %>% filter(Attrition == "No")
go <- Comp %>% filter(Attrition == "Yes")

smallstay <- stay[-c(3,4,6,9,13,17,19,23,24)]
meanstay <- colMeans(smallstay)

smallstay <- rbind(smallstay, meanstay)

smallgo <- go[-c(3,4,6,9,13,17,19,23,24)]
meango <- colMeans(smallgo)

smallgo <- rbind(smallgo, meango)


allmeans <- data.frame(matrix(NA, nrow = 1, ncol = 28))
for (i in 1:28) {
  allmeans[,i] <- (smallstay[731,i] - smallgo[141,i]) / (smallstay[731,i] + smallgo[141,i])
}
colnames(allmeans) <- colnames(smallgo)

amr <- data.frame(r1=names(allmeans),t(allmeans))
colnames(amr) <- c("ID","value")

x <- amr[order(amr$value),]
x$value <- x$value * 100

x$line <- ifelse(x$value < 0, "below", "above")

ggplot(x, aes(x=reorder(ID, value), y=value)) + 
  geom_bar(stat='identity', aes(fill=line), width=.5)  +
  scale_fill_manual(name="Percentage Difference", 
                    labels = c("Above Average", "Below Average"), 
                    values = c("above"="#00ba38", "below"="#f8766d")) + 
  labs(x="Employee Data", subtitle="Normalised Percentage Difference between Attrition and Retention", 
       title= "Employee Stats - Diverging Bars") + 
  coord_flip()

# Data Prep

percentages <- data.frame(perc = 1:37)
percentages$perc = 0

# Plot charts for each contributing factor
Comp %>% select(Attrition, StockOptionLevel) %>% ggpairs(aes(color=Attrition))
Comp %>% select(Attrition, YearsInCurrentRole) %>% ggpairs(aes(color=Attrition))
Comp %>% select(Attrition, TurnoverRatio) %>% ggpairs(aes(color=Attrition))

Comp %>% select(Attrition, StockOptionLevel, YearsInCurrentRole, TurnoverRatio) %>% ggpairs(aes(color=Attrition))

###############################
# Knn
## First find the best k-factor
accs = data.frame(accuracy = numeric(30), k = numeric(30))

for(i in 1:30)
{
  classifications = knn(train[,c(2,33)],test[,c(2,33)],train$Attrition, prob = TRUE, k = i)
  table(test$Attrition,classifications)
  CM = confusionMatrix(table(test$Attrition,classifications))
  accs$accuracy[i] = CM$overall[1]
  accs$k[i] = i
}

plot(accs$k,accs$accuracy, type = "l", xlab = "k", ylab = "Accuracy", main = "K-factor vs Accuracy") 

# plot knn
test %>% ggplot(aes(x = Age, TurnoverRatio,color = Attrition)) + geom_point() + ggtitle("Age vs Gender") + theme(plot.title = element_text(hjust = 0.5))
train %>% ggplot(aes(x = Age, DistanceFromHome,color = Attrition)) + geom_point() + ggtitle("Age vs Gender") + theme(plot.title = element_text(hjust = 0.5))

# knn
classifications = knn(train[,c(2,33)],test[,c(2,33)],train$Attrition, prob = TRUE, k = 10)
table(test$Attrition,classifications)
CM = confusionMatrix(table(test$Attrition,classifications))
CM

# NB Model and Confusion Matrix
model = naiveBayes(train[,c(2,29,33,37)],factor(train$Attrition, labels = c("No", "Yes")))
table(factor(test$Attrition, labels = c("No", "Yes")),predict(model,test[,c(2,29,33,37)]))
CM = confusionMatrix(table(factor(test$Attrition, labels = c("No", "Yes")),predict(model,test[,c(2,29,33,37)])))
CM

#################################







```
